{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('Basics') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|transaction_date|member_type|           member_id|gender|product|quantity|amount|  age|card_type|branch_name|region|category_name|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|      2018-04-01|     member|ff96777d-cfda-11e...|FEMALE|   3267|      16|  5100|30-35|  REGULAR|    E_Store|     3|  FROZEN FOOD|\n",
      "|      2018-04-09|     member|00d89024-cfdb-11e...|FEMALE|   6748|       1|  1100|55-60|  REGULAR|    A_Store|     1|          PET|\n",
      "|      2018-04-01|     member|00858b3b-cfdb-11e...|FEMALE|    420|       4|  5300|55-60|  REGULAR|    A_Store|     1|          PET|\n",
      "|      2018-04-13|     member|001035ed-cfdb-11e...|FEMALE|   3178|      16|  5600|45-50|  REGULAR|    A_Store|     1|      GADGETS|\n",
      "|      2018-04-15|     member|ff5fafeb-cfda-11e...|FEMALE|   2727|      19|  7600|25-30|  REGULAR|    A_Store|     1|      CLOTHES|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2018 = spark.read.csv(f\"C:/Users/gyalm/OneDrive/Desktop/churn_prediction/churn_prediction/data/week2_data_for_student_lab.csv.gz\", inferSchema=True, header=True)\n",
    "df_2018.show(5)\n",
    "df_2018.createOrReplaceTempView(\"df_2018_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transaction_date',\n",
       " 'member_type',\n",
       " 'member_id',\n",
       " 'gender',\n",
       " 'product',\n",
       " 'quantity',\n",
       " 'amount',\n",
       " 'age',\n",
       " 'card_type',\n",
       " 'branch_name',\n",
       " 'region',\n",
       " 'category_name']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|count(DISTINCT category_name)|\n",
      "+-----------------------------+\n",
      "|                           10|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT COUNT(DISTINCT category_name) FROM df_2018_view''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|category_name|\n",
      "+-------------+\n",
      "|  ACCESSORIES|\n",
      "|   APPLIANCES|\n",
      "|     CLEANERS|\n",
      "|      CLOTHES|\n",
      "|         FOOD|\n",
      "|  FROZEN FOOD|\n",
      "|      GADGETS|\n",
      "|     HARDWARE|\n",
      "|          PET|\n",
      "|        SHOES|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT DISTINCT category_name FROM df_2018_view ORDER BY category_name ASC''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|PARTITION_MONTH|total_member_id|\n",
      "+---------------+---------------+\n",
      "|     2018-04-01|          59143|\n",
      "|     2018-05-01|          84325|\n",
      "|     2018-06-01|          89658|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "WITH customers_in_april AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-04-01' AND '2018-04-30'\n",
    "), \n",
    "customers_in_april_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_april AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-01-01' AND '2018-03-31'\n",
    "), \n",
    "aggregated_total_txns_in_april AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-01-31' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-02-01' AND '2018-02-28' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-04-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_april_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "customers_in_may AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-05-01' AND '2018-05-31'\n",
    "), \n",
    "customers_in_may_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_may AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-02-01' AND '2018-04-30'\n",
    "), \n",
    "aggregated_total_txns_in_may AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-02-01' AND '2018-02-28' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-04-01' AND '2018-04-30' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-05-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_may_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "customers_in_june AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-06-01' AND '2018-06-30'\n",
    "), \n",
    "customers_in_june_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_june AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-03-01' AND '2018-05-31'\n",
    "), \n",
    "aggregated_total_txns_in_june AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-04-01' AND '2018-04-30' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-05-01' AND '2018-05-31' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-06-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_june_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "union_all_aggregated_txns AS (\n",
    "  SELECT * FROM aggregated_total_txns_in_april\n",
    "  UNION ALL\n",
    "  SELECT * FROM aggregated_total_txns_in_may\n",
    "  UNION ALL\n",
    "  SELECT * FROM aggregated_total_txns_in_june\n",
    ")\n",
    "SELECT\n",
    "    PARTITION_MONTH,\n",
    "    COUNT(member_id) AS total_member_id\n",
    "FROM\n",
    "    union_all_aggregated_txns\n",
    "GROUP BY\n",
    "    PARTITION_MONTH\n",
    "ORDER BY\n",
    "    PARTITION_MONTH\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------+\n",
      "|target|cnt_member_id|cntd_member_id|\n",
      "+------+-------------+--------------+\n",
      "|     1|        15873|         15873|\n",
      "|     0|        34794|         34794|\n",
      "+------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "WITH\n",
    "customers_in_july AS (\n",
    "SELECT\n",
    "  DISTINCT member_id\n",
    "FROM\n",
    "  df_2018_view\n",
    "WHERE\n",
    "  transaction_date BETWEEN '2018-07-01' AND '2018-07-31'\n",
    ")\n",
    ",customers_in_july_joined_with_past_transactions AS (\n",
    "SELECT\n",
    "  a.member_id\n",
    "  ,b.quantity\n",
    "  ,b.transaction_date\n",
    "FROM\n",
    "  customers_in_july AS a\n",
    "LEFT JOIN\n",
    "  df_2018_view AS b\n",
    "ON\n",
    "  a.member_id = b.member_id\n",
    "AND\n",
    "  b.transaction_date BETWEEN '2018-01-01' AND '2018-06-30'\n",
    ")\n",
    ",aggregated_total_txns_per_month AS (\n",
    "SELECT\n",
    "   member_id\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-04-01' AND '2018-04-30' THEN quantity ELSE 0 END) AS pm3_total_txn\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-05-01' AND '2018-05-31' THEN quantity ELSE 0 END) AS pm2_total_txn\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-06-01' AND '2018-06-30' THEN quantity ELSE 0 END) AS pm1_total_txn\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-07-01' AND '2018-07-31' THEN quantity ELSE 0 END) AS pm0_total_txn\n",
    "  ,'2018-07-01' AS PARTITION_MONTH\n",
    "FROM\n",
    "  customers_in_july_joined_with_past_transactions\n",
    "GROUP BY\n",
    "  member_id\n",
    ")\n",
    ",customers_with_target_definition AS (\n",
    "SELECT\n",
    "  *\n",
    "  ,CASE\n",
    "    WHEN pm1_total_txn = 0 AND pm2_total_txn = 0 AND pm3_total_txn = 0 THEN 1\n",
    "    ELSE 0\n",
    "    END AS target\n",
    "FROM\n",
    "  aggregated_total_txns_per_month\n",
    ")\n",
    ",customers_joined_with_features AS (\n",
    "SELECT\n",
    "  a.member_id\n",
    "  ,b.amount\n",
    "  ,b.category_name\n",
    "  ,b.transaction_date\n",
    "FROM\n",
    "  customers_in_july AS a\n",
    "LEFT JOIN\n",
    "  df_2018_view AS b\n",
    "ON\n",
    "  a.member_id = b.member_id\n",
    "AND\n",
    "  b.transaction_date BETWEEN '2018-01-01' AND '2018-03-31'\n",
    ")\n",
    ",aggregated_categories AS (\n",
    "SELECT\n",
    "   member_id\n",
    "\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('ACCESSORIES') THEN amount ELSE 0 END) AS pm_accessories\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('APPLIANCES') THEN amount ELSE 0 END) AS pm_appliances\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('CLEANERS') THEN amount ELSE 0 END) AS pm_cleaners\n",
    "\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('CLOTHES') THEN amount ELSE 0 END) AS pm_clothes\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('FOOD') THEN amount ELSE 0 END) AS pm_food\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('FROZEN FOOD') THEN amount ELSE 0 END) AS pm_frozen_food\n",
    "\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('GADGETS') THEN amount ELSE 0 END) AS pm_gadgets\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('HARDWARE') THEN amount ELSE 0 END) AS pm_hardware\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('PET') THEN amount ELSE 0 END) AS pm_pet\n",
    "\n",
    "  ,SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-03-31' AND category_name IN ('SHOES') THEN amount ELSE 0 END) AS pm_shoes\n",
    "\n",
    "FROM\n",
    "  customers_joined_with_features\n",
    "GROUP BY\n",
    "  member_id\n",
    ")\n",
    ",customers_with_target_joined_with_features AS (\n",
    "SELECT\n",
    "  a.member_id\n",
    "  ,a.target\n",
    "  ,b.pm_accessories\n",
    "  ,b.pm_appliances\n",
    "  ,b.pm_cleaners\n",
    "  ,b.pm_clothes\n",
    "  ,b.pm_food\n",
    "  ,b.pm_frozen_food\n",
    "  ,b.pm_gadgets\n",
    "  ,b.pm_hardware\n",
    "  ,b.pm_pet\n",
    "  ,b.pm_shoes\n",
    "FROM\n",
    "  customers_with_target_definition AS a\n",
    "LEFT JOIN\n",
    "  aggregated_categories AS b\n",
    "ON\n",
    "  a.member_id = b.member_id\n",
    ")\n",
    "\n",
    ",count_customers_with_target_definition AS (\n",
    "SELECT\n",
    "  target\n",
    "  ,COUNT(member_id) AS cnt_member_id\n",
    "  ,COUNT(DISTINCT member_id) AS cntd_member_id\n",
    "FROM\n",
    "  customers_with_target_definition\n",
    "GROUP BY\n",
    "  target\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  count_customers_with_target_definition\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.72753130802354"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(34794/(15832+34794))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Week 3: Data Engineering\n",
    "\n",
    "With the goal of identifying customers that churned based on past three months with no transactions, a comparison between the performance and behavorial window was postulated. The performance window is inclusive of the months of April to June with the target of viewing the net churn rate up until customers in July - thus, the target selection consists of the member_id, quantity, and transaction_date. The behavorial window subsist of January to March, including the feature selection of member_id, category_name, amount, and transaction_date, in order to balance the distribution of data.\n",
    "\n",
    "Data selection begins with `customers_in_july`, filtering distinct `member_id` values who transacted in July 2018. Data cleaning occurs in `customers_in_july_joined_with_past_transactions`, where a `LEFT JOIN` links July customers with their past transactions from January to June, ensuring historical/trend continuity. Feature selection is implemented in `customers_joined_with_features`, extracting `member_id`, `amount`, `category_name`, and `transaction_date` from January to March for behavioral analysis. Class balancing is introduced in `customers_with_target_definition`, where churn (`target=1`) is assigned to customers with zero transactions in April, May, and June. Feature engineering occurs in `aggregated_categories`, summing transaction amounts per category for January–March, to enrich feature selection in the performance window profile. Data augmentation happens in `customers_with_target_joined_with_features`, merging churn labels with the behavorial window of expenditure.Lastly, data standardization is applied in `count_customers_with_target_definition`, aggregating customer counts per churn status.\n",
    "\n",
    "To calculate the overall churn rate of 68.72%, counted customers of those that have had zero transactions aggregated for the past 3 months of the performance window (`target=0`) were divided by the sum of customers that have churned in the past 3 months (`target=1`) and customers that have had zero transactions in the past 3 months, multiplied by a 100 to get the percentage value. Overall, a churn rate of 68.72% indicates a significant portion of the customer base has become inactive over the past three months, suggesting potential issues in customer engagement, satisfaction, or retention strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
