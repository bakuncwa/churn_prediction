{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('Basics') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|transaction_date|member_type|           member_id|gender|product|quantity|amount|  age|card_type|branch_name|region|category_name|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|      2018-01-17|     member|ffc9e419-cfda-11e...|FEMALE|    420|       2|  5300|50-55|  REGULAR|    D_Store|     2|          PET|\n",
      "|      2018-04-10|     member|ff39d825-cfda-11e...|  MALE|     69|       4|  7100|40-45|  REGULAR|    D_Store|     2|     CLEANERS|\n",
      "|      2018-02-19|     member|ff90d1f8-cfda-11e...|FEMALE|   1015|      18|  8100|40-45|  REGULAR|    J_Store|     1|          PET|\n",
      "|      2018-01-27|     member|ffd5caf9-cfda-11e...|  MALE|     69|      11|  7100|18-25|  REGULAR|    H_Store|     4|     CLEANERS|\n",
      "|      2018-05-07|     member|ff92f50e-cfda-11e...|FEMALE|   3456|      13|  5200|55-60|  REGULAR|    B_Store|     1|         FOOD|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2018 = spark.read.csv(f\"C:/Users/gyalm/OneDrive/Desktop/churn_prediction/churn_prediction/data/week2_for_teacher_demo.csv.gz\", inferSchema=True, header=True)\n",
    "df_2018.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.createOrReplaceTempView(\"df_2018_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|transaction_date|member_type|           member_id|gender|product|quantity|amount|  age|card_type|branch_name|region|category_name|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "|      2018-01-17|     member|ffc9e419-cfda-11e...|FEMALE|    420|       2|  5300|50-55|  REGULAR|    D_Store|     2|          PET|\n",
      "|      2018-04-10|     member|ff39d825-cfda-11e...|  MALE|     69|       4|  7100|40-45|  REGULAR|    D_Store|     2|     CLEANERS|\n",
      "|      2018-02-19|     member|ff90d1f8-cfda-11e...|FEMALE|   1015|      18|  8100|40-45|  REGULAR|    J_Store|     1|          PET|\n",
      "|      2018-01-27|     member|ffd5caf9-cfda-11e...|  MALE|     69|      11|  7100|18-25|  REGULAR|    H_Store|     4|     CLEANERS|\n",
      "|      2018-05-07|     member|ff92f50e-cfda-11e...|FEMALE|   3456|      13|  5200|55-60|  REGULAR|    B_Store|     1|         FOOD|\n",
      "+----------------+-----------+--------------------+------+-------+--------+------+-----+---------+-----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT * FROM df_2018_view LIMIT 5''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|MemberId|\n",
      "+--------+\n",
      "|  302262|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT COUNT(DISTINCT member_id) AS MemberId FROM df_2018_view''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|MemberId|\n",
      "+--------+\n",
      "|   67717|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT COUNT(DISTINCT member_id) AS MemberId FROM df_2018_view WHERE transaction_date LIKE \"%2018-04%\"''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_txn_window = [\n",
    "#     ('2018-01-01', '2018-01-31', 'pm1_total_txn'),\n",
    "#     ('2018-02-01', '2018-02-28', 'pm2_total_txn'),\n",
    "#     ('2018-03-01', '2018-03-31', 'pm3_total_txn'),\n",
    "#     ('2018-04-01', '2018-04-30', 'pm4_total_txn'),\n",
    "#     ('2018-05-01', '2018-05-31', 'pm5_total_txn'),\n",
    "#     ('2018-06-01', '2018-06-30', 'pm6_total_txn')]\n",
    "\n",
    "# sum_txn_window = \",\\n        \".join([\n",
    "#     f\"SUM(CASE WHEN transaction_date BETWEEN '{start_date}' AND '{end_date}' THEN quantity ELSE 0 END) AS {past_month}\"\n",
    "# for start_date, end_date, past_month in month_txn_window\n",
    "# ])\n",
    "\n",
    "# spark.sql(f'''\n",
    "# WITH\n",
    "# aggregated_customers AS (\n",
    "#     SELECT DISTINCT member_id\n",
    "#     FROM df_2018_view\n",
    "#     WHERE transaction_date BETWEEN '{month_txn_window[::len(month_txn_window)][0][0]}' AND '{month_txn_window[::-1][0][1]}'\n",
    "# ),\n",
    "\n",
    "# aggregated_customers_with_past_txns AS (\n",
    "#     SELECT DISTINCT\n",
    "#         a.member_id,\n",
    "#         b.quantity,\n",
    "#         b.transaction_date\n",
    "#     FROM\n",
    "#         aggregated_customers AS a\n",
    "#     LEFT JOIN\n",
    "#         df_2018_view AS b\n",
    "#     ON\n",
    "#         a.member_id = b.member_id\n",
    "#     WHERE\n",
    "#         b.transaction_date BETWEEN '{month_txn_window[::len(month_txn_window)][0][0]}' AND '{month_txn_window[::-1][0][1]}'\n",
    "# ),\n",
    "\n",
    "# aggregated_total_txns_per_month AS (\n",
    "#     SELECT DISTINCT\n",
    "#         member_id,\n",
    "#         {sum_txn_window}\n",
    "#     FROM\n",
    "#         aggregated_customers_with_past_txns\n",
    "#     GROUP BY\n",
    "#         member_id\n",
    "# )\n",
    "\n",
    "# SELECT DISTINCT\n",
    "#     member_id,\n",
    "#     {\", \".join(list(map(lambda x: x[2], month_txn_window)))},\n",
    "#     CASE \n",
    "#         WHEN { \" AND \".join(list(map(lambda x: f\"{x[2]} = 0\", month_txn_window))) } THEN 'Churned'\n",
    "#         ELSE 'Active'\n",
    "#     END AS churn_status\n",
    "# FROM\n",
    "#     aggregated_total_txns_per_month\n",
    "# LIMIT \n",
    "# 20\n",
    "# ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|PARTITION_MONTH|total_member_id|\n",
      "+---------------+---------------+\n",
      "|     2018-04-01|          28579|\n",
      "|     2018-05-01|          41565|\n",
      "|     2018-06-01|          45672|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "WITH customers_in_april AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-04-01' AND '2018-04-30'\n",
    "), \n",
    "customers_in_april_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_april AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-01-01' AND '2018-03-31'\n",
    "), \n",
    "aggregated_total_txns_in_april AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-01-01' AND '2018-01-31' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-02-01' AND '2018-02-28' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-04-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_april_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "customers_in_may AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-05-01' AND '2018-05-31'\n",
    "), \n",
    "customers_in_may_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_may AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-02-01' AND '2018-04-30'\n",
    "), \n",
    "aggregated_total_txns_in_may AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-02-01' AND '2018-02-28' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-04-01' AND '2018-04-30' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-05-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_may_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "customers_in_june AS (\n",
    "  SELECT DISTINCT member_id\n",
    "  FROM df_2018_view\n",
    "  WHERE transaction_date BETWEEN '2018-06-01' AND '2018-06-30'\n",
    "), \n",
    "customers_in_june_joined_with_past_3_months_txn AS (\n",
    "  SELECT\n",
    "    a.member_id, \n",
    "    b.quantity, \n",
    "    b.transaction_date\n",
    "  FROM\n",
    "    customers_in_june AS a\n",
    "  LEFT JOIN\n",
    "    df_2018_view AS b\n",
    "  ON\n",
    "    a.member_id = b.member_id\n",
    "  WHERE\n",
    "    b.transaction_date BETWEEN '2018-03-01' AND '2018-05-31'\n",
    "), \n",
    "aggregated_total_txns_in_june AS (\n",
    "  SELECT\n",
    "    member_id, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-03-01' AND '2018-03-31' THEN quantity ELSE 0 END) AS pm3_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-04-01' AND '2018-04-30' THEN quantity ELSE 0 END) AS pm2_total_txn, \n",
    "    SUM(CASE WHEN transaction_date BETWEEN '2018-05-01' AND '2018-05-31' THEN quantity ELSE 0 END) AS pm1_total_txn,\n",
    "    '2018-06-01' AS PARTITION_MONTH\n",
    "  FROM\n",
    "    customers_in_june_joined_with_past_3_months_txn\n",
    "  GROUP BY\n",
    "    member_id\n",
    "),\n",
    "union_all_aggregated_txns AS (\n",
    "  SELECT * FROM aggregated_total_txns_in_april\n",
    "  UNION ALL\n",
    "  SELECT * FROM aggregated_total_txns_in_may\n",
    "  UNION ALL\n",
    "  SELECT * FROM aggregated_total_txns_in_june\n",
    ")\n",
    "SELECT\n",
    "    PARTITION_MONTH,\n",
    "    COUNT(member_id) AS total_member_id\n",
    "FROM\n",
    "    union_all_aggregated_txns\n",
    "GROUP BY\n",
    "    PARTITION_MONTH\n",
    "ORDER BY\n",
    "    PARTITION_MONTH\n",
    "''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
